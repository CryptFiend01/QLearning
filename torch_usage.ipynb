{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(1)\n",
    "w = torch.full([1], 2.)\n",
    "w.requires_grad_()\n",
    "print(x)\n",
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.ones(1)\n",
    "mse = F.mse_loss(pred, x*w)\n",
    "print(mse)\n",
    "torch.autograd.grad(mse, [w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = F.mse_loss(pred, x*w)\n",
    "mse.backward()\n",
    "print(w.grad)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1., 1., 1.])\n",
    "a.shape\n",
    "b = a.reshape((1, 3))\n",
    "b.shape\n",
    "\n",
    "c = b.view((1, 3, 1))\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical\n",
    "\n",
    "probs = torch.tensor([0.7, 0.12, 0.1, 0.08])\n",
    "m = Categorical(probs)\n",
    "counts = [0, 0, 0, 0]\n",
    "for i in range(100):\n",
    "    a = m.sample()\n",
    "    counts[a.item()] += 1\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "torch.Size([1, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Conv2d(1, 3, 5, 1, 2)\n",
    "x = torch.rand(1, 1, 28, 28)\n",
    "print(x.shape)\n",
    "out = layer.forward(x)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.rand(16, 3, 5, 5)\n",
    "print(w.shape)\n",
    "b = torch.rand(16)\n",
    "print(b.shape)\n",
    "\n",
    "x = torch.rand(1, 3, 28, 28)\n",
    "out = F.conv2d(x, w, b, stride=1, padding=1)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3000)\n",
      "tensor(0.8250)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([0.7, 0.2, 0.8, 1.6])\n",
    "print(a.sum())\n",
    "print(a.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 3., 2., 3., 1.])\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "losses.append(torch.Tensor([1., 1., 3.]))\n",
    "losses.append(torch.Tensor([2., 3., 1.]))\n",
    "losses = torch.cat(losses)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5556)\n"
     ]
    }
   ],
   "source": [
    "t = torch.Tensor([[1.,2.,3.],[4.,3.,2.],[3.,3.,2.]])\n",
    "print(t.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4), padding=(3, 3))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): ReLU()\n",
      "  (6): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n",
      "torch.Size([2, 256])\n",
      "256\n",
      "tensor([[0.0039, 0.0040, 0.0039, 0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0042, 0.0041,\n",
      "         0.0043, 0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0041, 0.0039, 0.0040, 0.0040,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0040, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0039,\n",
      "         0.0040, 0.0039, 0.0039, 0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0041,\n",
      "         0.0041, 0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0039, 0.0040,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0040, 0.0039, 0.0039, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0041, 0.0042, 0.0039, 0.0040, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0039, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040,\n",
      "         0.0039, 0.0039, 0.0040, 0.0039, 0.0040, 0.0039, 0.0039, 0.0040, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0040, 0.0039, 0.0039, 0.0039, 0.0040, 0.0039,\n",
      "         0.0039, 0.0039, 0.0040, 0.0040, 0.0039, 0.0039, 0.0039, 0.0041, 0.0039,\n",
      "         0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0039, 0.0039,\n",
      "         0.0041, 0.0040, 0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040,\n",
      "         0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0040, 0.0041,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0041, 0.0042, 0.0041, 0.0040,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039],\n",
      "        [0.0039, 0.0040, 0.0039, 0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0042, 0.0040,\n",
      "         0.0043, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0039, 0.0040, 0.0039, 0.0039, 0.0039, 0.0040, 0.0039, 0.0041, 0.0040,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0041, 0.0041, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0041, 0.0040, 0.0039, 0.0039,\n",
      "         0.0040, 0.0039, 0.0039, 0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0041, 0.0040,\n",
      "         0.0042, 0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0039, 0.0039, 0.0040, 0.0039, 0.0040, 0.0040, 0.0039, 0.0039, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0042, 0.0039, 0.0039, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0040,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0041,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0039, 0.0041, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0040, 0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0041, 0.0040,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0040, 0.0039, 0.0039, 0.0040, 0.0040, 0.0039,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0041, 0.0039,\n",
      "         0.0041, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0041, 0.0039, 0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
      "         0.0039, 0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0039,\n",
      "         0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0039, 0.0041,\n",
      "         0.0040, 0.0039, 0.0039, 0.0039, 0.0039, 0.0041, 0.0042, 0.0040, 0.0040,\n",
      "         0.0039, 0.0039, 0.0039, 0.0039]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mod = nn.Sequential(\n",
    "    nn.Conv2d(3, 32, kernel_size=8, stride=4, padding=3),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten()\n",
    ")\n",
    "\n",
    "print(mod)\n",
    "\n",
    "x = torch.rand((2, 3, 16, 16))\n",
    "y = mod(x)\n",
    "print(y.shape)\n",
    "print(y.shape[1])\n",
    "action = F.softmax(y, dim=1)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5]])\n",
      "tensor([5])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[5]])\n",
    "print(t)\n",
    "x = t.squeeze(1)\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d33df38dbe8955aef30b1eb444d3d3968a89b555374e01995e2b4794739c3e48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

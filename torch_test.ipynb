{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\"data\", train=True, download=True, transform=ToTensor())\n",
    "test_data = datasets.FashionMNIST(\"data\", train=False, download=True, transform=ToTensor())\n",
    "train_loader = DataLoader(train_data, batch_size=64)\n",
    "test_loader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(cols*rows):\n",
    "    idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[idx]\n",
    "    figure.add_subplot(rows, cols, i+1)\n",
    "    # plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return self.net(x)\n",
    "\n",
    "model = Network().to(\"cpu\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "sgd = optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train(data: DataLoader, model: Network, lossfn, sgd):\n",
    "    size = len(data.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(data):\n",
    "        pred = model(X)\n",
    "        loss = lossfn(pred, y)\n",
    "        sgd.zero_grad()\n",
    "        loss.backward()\n",
    "        sgd.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"batch: {batch} loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data: DataLoader, model: Network, lossfn):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data:\n",
    "            pred = model(X)\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    print(f\"Test accuracy: {correct / len(data.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(f\"epoch {i} ------------------\")\n",
    "    train(train_loader, model, loss_fn, sgd)\n",
    "    test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(data):\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(data)), data)\n",
    "    plt.legend(['value'], loc=\"upper right\")\n",
    "    plt.xlabel('step')\n",
    "    plt.ylabel('value')\n",
    "    plt.show()\n",
    "\n",
    "def plot_image(img, label, name):\n",
    "    plt.figure()\n",
    "    for i in range(6):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(img[i][0] * 0.3081 + 0.1307, cmap='gray', interpolation='none')\n",
    "        plt.title(f\"{name}: {label[i].item()}\")\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "def one_hot(label, depth=10):\n",
    "    out = torch.zeros(label.size(0), depth)\n",
    "    idx = torch.LongTensor(label).view(-1, 1)\n",
    "    out.scatter_(dim=1, index=idx, value=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "tf_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "tf_test = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "# train_loader = DataLoader(\"mnist_data\", train=True, download=True, transform=tf, batch_size=512, shuffle=True)\n",
    "# test_loader = DataLoader(\"mnist_data\", train=False, download=True, transform=tf, batch_size=512, shuffle=False)\n",
    "mnist_train = datasets.MNIST(\"mnist_data\", train=True, transform=tf_train, download=True)\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "mnist_test = datasets.MNIST(\"mnist_data\", train=False, transform=tf_test, download=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(MnistNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MnistNet()\n",
    "sgd = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data: DataLoader, net: MnistNet, sgd):\n",
    "    losses = []\n",
    "    net.train()\n",
    "    for epoch in range(3):\n",
    "        for batch, (x, y) in enumerate(data):\n",
    "            # x = x.view(x.size(0), 28*28)\n",
    "            out = net(x)\n",
    "            y_onehot = one_hot(y)\n",
    "            loss = F.mse_loss(out, y_onehot)\n",
    "            sgd.zero_grad()\n",
    "            loss.backward()\n",
    "            sgd.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            if batch % 10 == 0:\n",
    "                print(f\"\\repoch {epoch} ===========> batch {batch} loss {loss.item()}\")\n",
    "                # sys.stdout.write(f\"\\repoch {epoch} ===========> batch {batch} loss {loss.item()}\")\n",
    "                # sys.stdout.flush()\n",
    "        #print(\"\")\n",
    "    plot_curve(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_loader, net, sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net):\n",
    "    total = 0\n",
    "    for x, y in test_loader:\n",
    "        # x = x.view(x.size(0), 28*28)\n",
    "        out = net(x)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct = pred.eq(y).sum().float().item()\n",
    "        total += correct\n",
    "    print(f\"test acc: {total / len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "print(x.shape, y.shape, x.min(), x.max())\n",
    "out = net(x)\n",
    "pred = out.argmax(dim=1)\n",
    "plot_image(x, pred, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, 1, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, 1, 1)\n",
    "        self.fc1 = nn.Linear(16 * 28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CnnNet()\n",
    "lossfn = nn.CrossEntropyLoss()\n",
    "adam = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "print(x.shape, y.shape, x.min(), x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traincnn(train_loader, net, adam):\n",
    "    losses = []\n",
    "    net.train()\n",
    "    for i in range(3):\n",
    "        for batch, (x, y) in enumerate(train_loader):\n",
    "            print(x.shape)\n",
    "            out = net(x)\n",
    "            y_onehot = one_hot(y)\n",
    "            print(f'out: {out.shape}')\n",
    "            print(f'y_onehot: {y_onehot.shape}')\n",
    "            loss = F.mse_loss(out, y_onehot)\n",
    "            adam.zero_grad()\n",
    "            loss.backward()\n",
    "            adam.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            if batch % 10 == 0:\n",
    "                print(f\"\\repoch {i} ===========> batch {batch} loss {loss.item()}\")\n",
    "    plot_curve(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traincnn(train_loader, net, adam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d33df38dbe8955aef30b1eb444d3d3968a89b555374e01995e2b4794739c3e48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
